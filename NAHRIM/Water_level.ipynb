{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lLZfeZp7tV-Y"
      },
      "outputs": [],
      "source": [
        "!pip install requests pandas beautifulsoup4 lxml\n",
        "!mkdir -p out"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import requests\n",
        "import pandas as pd\n",
        "from io import StringIO\n",
        "from datetime import datetime, timezone\n",
        "\n",
        "URL = \"https://publicinfobanjir.water.gov.my/aras-air/data-paras-air/aras-air-data/\"\n",
        "STATE_CODES = [\"PLS\", \"KDH\", \"PNG\", \"PRK\", \"SEL\", \"WLH\",\"PTJ\", \"NSN\", \"MLK\", \"JHR\", \"PHG\", \"TRG\", \"KEL\", \"SRK\", \"SAB\", \"WLP\" ]\n",
        "OUTFILE = \"waterlevel_combined_raw.csv\"\n",
        "HEADERS = {\"User-Agent\": \"Mozilla/5.0\"}\n",
        "\n",
        "TARGET_HEADER = [\n",
        "    \"No.\",\n",
        "    \"Station ID\",\n",
        "    \"Station Name\",\n",
        "    \"District\",\n",
        "    \"Main Basin\",\n",
        "    \"Sub River Basin\",\n",
        "    \"Last Updated\",\n",
        "    \"Water Level (m) (Graph)\",\n",
        "    \"Threshold Normal\",\n",
        "    \"Threshold Alert\",\n",
        "    \"Threshold Warning\",\n",
        "    \"Threshold Danger\",\n",
        "    \"State\"\n",
        "]\n",
        "\n",
        "#-------------------MAIN LOGIC-------------------\n",
        "def utc_ts():\n",
        "    return datetime.now(timezone.utc).strftime(\"%Y%m%dT%H%M%SZ\")\n",
        "\n",
        "def main():\n",
        "    all_states = []\n",
        "\n",
        "    for s in STATE_CODES:\n",
        "        params = {\"state\": s, \"district\": \"ALL\", \"station\": \"ALL\", \"lang\": \"en\"}\n",
        "        resp = requests.get(URL, params=params, headers=HEADERS, timeout=60)\n",
        "        resp.raise_for_status()\n",
        "\n",
        "        # simplest: let pandas decide header (first row as header)\n",
        "        df = pd.read_html(StringIO(resp.text))[0]\n",
        "        df[\"state_param\"] = s\n",
        "\n",
        "        all_states.append(df)\n",
        "        print(f\"Fetched {s}: {len(df)} rows\")\n",
        "\n",
        "    combined = pd.concat(all_states, ignore_index=True)\n",
        "    combined.columns = TARGET_HEADER\n",
        "    os.makedirs(os.path.dirname(OUTFILE) or \".\", exist_ok=True)\n",
        "    combined.to_csv(OUTFILE, index=False)\n",
        "\n",
        "    print(\"\\nâœ… Raw combined CSV saved:\", os.path.abspath(OUTFILE))\n",
        "    print(\"Total rows:\", len(combined))\n",
        "    print(combined.head())\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "UZOIoLUstW34"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}