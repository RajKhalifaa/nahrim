# -*- coding: utf-8 -*-
"""waterquality_MyEQMS

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1RGkng9A5dvwoHwxTGgBsrX6xh4JVmFgA
"""

!pip install scrapy

# Commented out IPython magic to ensure Python compatibility.
# %%writefile eqmp_crwqi_spider.py
# import scrapy
# import json
# 
# 
# STATE_IDS = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16]
# 
# BASE_URL = "https://eqms.doe.gov.my/api3/publicportalrqims/crwqi"
# 
# class EqmpCrwqiSpider(scrapy.Spider):
#     name = "eqmp_crwqi_spider"
#     custom_settings = {"LOG_LEVEL": "INFO"}
# 
#     def start_requests(self):
#         for sid in STATE_IDS:
#             url = f"{BASE_URL}?stateid={sid}"
#             self.logger.info(f"[WQI] Fetching state_id={sid} -> {url}")
#             yield scrapy.Request(
#                 url=url,
#                 callback=self.parse_state,
#                 cb_kwargs={"state_id": sid}
#             )
# 
#     def parse_state(self, response, state_id):
#         try:
#             payload = json.loads(response.text)
#         except json.JSONDecodeError:
#             self.logger.warning(f" Failed to decode JSON for state_id={state_id}")
#             return
# 
#         rows = payload.get("crwqi", [])
#         if not rows:
#             self.logger.info(f"No 'crwqi' rows for state_id={state_id}")
#             return
# 
#         for d in rows:
#             d["state_id"] = state_id
#             # yield each record as an item
#             yield d
#

!scrapy runspider eqmp_crwqi_spider.py -O eqmp_crwqi.json

import pandas as pd

df = pd.read_json("eqmp_crwqi.json")
print("EQMP rows:", len(df))
df.head()