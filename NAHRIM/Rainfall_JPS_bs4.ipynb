{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qTiOFoZpfsUB"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import requests\n",
        "import pandas as pd\n",
        "from bs4 import BeautifulSoup  # pip install beautifulsoup4\n",
        "\n",
        "URL = \"https://publicinfobanjir.water.gov.my/wp-content/themes/shapely/agency/searchresultrainfall.php\"\n",
        "HEADERS = {\"User-Agent\": \"Mozilla/5.0\"}  # look like a browser\n",
        "OUTFILE = \"rainfall_trend.csv\"\n",
        "STATE_CODES = [\"PLS\", \"KDH\", \"PNG\", \"PRK\", \"SEL\", \"WLH\",\"PTJ\", \"NSN\", \"MLK\", \"JHR\", \"PHG\", \"TRG\", \"KEL\", \"SRK\", \"SAB\", \"WLP\" ]\n",
        "\n",
        "#-----------------------------MAIN LOGIC-----------------------------\n",
        "def main():\n",
        "    all_states = []\n",
        "    for s in STATE_CODES:\n",
        "            params = { \"state\": s, \"district\": \"ALL\", \"station\": \"ALL\", \"loginStatus\": \"0\",  \"language\": \"1\" }\n",
        "            resp = requests.get(URL, params=params, headers=HEADERS, timeout=60)\n",
        "            resp.raise_for_status()\n",
        "            html = resp.text\n",
        "\n",
        "            soup = BeautifulSoup(html, \"html.parser\")\n",
        "            table = soup.find(\"table\", id=\"normaltable1\")\n",
        "            if table is None:\n",
        "                      raise RuntimeError(\"Could not find table with id 'normaltable1'\")\n",
        "\n",
        "            # ---------- Build column names ----------\n",
        "            ths = table.find(\"thead\").find_all(\"th\")\n",
        "            th_texts = [th.get_text(\" \", strip=True) for th in ths]\n",
        "\n",
        "             # Expected order\n",
        "             # 0: No.\n",
        "             # 1: Station ID\n",
        "             # 2: Station\n",
        "             # 3: District\n",
        "             # 4: Last Updated\n",
        "             # 5: Daily Rainfall (group label)  -> we skip this\n",
        "             # 6: Rainfall from Midnight (...)\n",
        "             # 7: Total 1 Hour (Now)\n",
        "             # 8..: date columns (under Daily Rainfall group)\n",
        "\n",
        "            base_cols = th_texts[0:5]           # No., Station ID, Station, District, Last Updated\n",
        "            date_cols = th_texts[8:]           # e.g. 12/11/2025, 13/11/2025, ...\n",
        "            tail_cols = th_texts[6:8]          # Rainfall from Midnight (...), Total 1 Hour (Now)\n",
        "\n",
        "            columns = base_cols + date_cols + tail_cols\n",
        "            ncols = len(columns)\n",
        "\n",
        "            # ---------- Extract body rows ----------\n",
        "            tbody = table.find(\"tbody\")\n",
        "            tds = [td.get_text(\" \", strip=True) for td in tbody.find_all(\"td\")]\n",
        "\n",
        "            # Group every ncols <td> into one row\n",
        "            rows = [tds[i:i + ncols] for i in range(0, len(tds), ncols)]\n",
        "\n",
        "            df = pd.DataFrame(rows, columns=columns)\n",
        "            df[\"state_param\"] = s\n",
        "\n",
        "            all_states.append(df)\n",
        "            print(f\"Fetched {s}: {len(df)} rows\")\n",
        "\n",
        "    combined = pd.concat(all_states, ignore_index=True)\n",
        "    os.makedirs(os.path.dirname(OUTFILE) or \".\", exist_ok=True)\n",
        "    combined.to_csv(OUTFILE, index=False)\n",
        "\n",
        "    print(\"\\nâœ… Raw combined CSV saved:\", os.path.abspath(OUTFILE))\n",
        "    print(\"Total rows:\", len(combined))\n",
        "    print(combined.head())\n",
        "\n",
        "if  __name__ == \"__main__\":\n",
        "   main()"
      ]
    }
  ]
}